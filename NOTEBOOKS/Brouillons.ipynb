{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of countries\n",
    "# files.upload()\n",
    "f=open('countries.txt', \"r\")\n",
    "content = f.read()\n",
    "f.close()\n",
    "list_cnt = content.lower().split(',')\n",
    "list_cnt = [s.strip() for s in list_cnt]\n",
    "\n",
    "# Cleaning strings in 'countries_en'\n",
    "df[['countries_en', 'countries']] = df[['countries_en', 'countries']].astype('object')\n",
    "df[['countries_en', 'countries']].fillna('unknown')\n",
    "df['countries_en'] = df['countries_en'].str.lower().apply(str)\n",
    "df['countries_en'] = df['countries_en'].str.replace('ô', 'o').str.replace('é', 'e')\n",
    "\n",
    "# Creating a new column with filtered list of countries\n",
    "split_remove = lambda x: tuple([s for s in x.split(',') if s in list_cnt])\n",
    "df['countries_en_tuple'] = df['countries_en'].apply(split_remove)\n",
    "# Creating a column with only one main (first) country\n",
    "df['countries_en_first'] = df['countries_en_tuple']\\\n",
    "                          .apply(lambda x: x[0] if len(x)!=0 else 'unknown')\n",
    "# Reordering the columns\n",
    "df = df.reindex(columns=move_cat_containing(df.columns,['countr'], 'first'))\n",
    "\n",
    "# Checking new columns\n",
    "cols = ['countries', 'countries_en', 'countries_en_first', 'countries_en_tuple']\n",
    "df[cols].sample(5)\n",
    "\n",
    "# Deleting old columns\n",
    "del df['countries'], df['countries_en']\n",
    "\n",
    "df['countries_en_first'].value_counts()[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data, dropping categories with less than 15 occurences\n",
    "multi_cat_cols = ['brand_owner', 'brands', 'countries_en_first', 'packaging',\n",
    "                  'labels', 'traces_tags', 'allergens',\n",
    "                  'main_category_en', 'categories_en','pnns2', 'pnns1']\n",
    "def uniq() : return x.nunique()\n",
    "def min_occ(x) : return min(x.value_counts())\n",
    "def max_occ(x) : return max(x.value_counts())\n",
    "n = 15\n",
    "def less_th_n(x,n=n) : return (x.value_counts()<n).sum()\n",
    "def more_th_n(x,n=n) : return (x.value_counts()>=n).sum()\n",
    "\n",
    "display(df[multi_cat_cols].agg([uniq, min_occ, max_occ, less_th_n, more_th_n]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ser_m = ser.str.split(',')\n",
    "    flat_values = pd.Series([item for sublist in ser_m for item in sublist])\n",
    "    cat_occ = flat_values.value_counts()\n",
    "    to_del = cat_occ[cat_occ>n].index\n",
    "    for s in to_del:\n",
    "        ser_m = ser.str.replace(s, '')\n",
    "    ser_m = ser_m.apply(lambda x: tuple([s.strip() for s in x.split(',')\\\n",
    "                                         if s.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = pd.DataFrame({'col1':['aede, abcd', 'dsqk, dsk, a f', 'cck, 3 p']})\n",
    "\n",
    "for s in ['ab', 'ds', '3']:\n",
    "     dtest['col1'] = dtest['col1'].str.replace(s, '')\n",
    "\n",
    "dtest['col1'].apply(lambda x: tuple([s.strip() for s in x.split(',') if s.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining groups of columns\n",
    "info_cols =  ['code', 'code_val', 'url', 'creator', 'created_datetime',\n",
    "               'product_name', 'ingredients_text']\n",
    "\n",
    "m_nutri_cols = ['fat_100g', 'carbohydrates_100g', 'proteins_100g',\n",
    "                'salt_100g', 'fiber_100g', 'saturated_fat_100g', 'sugars_100g']\n",
    "\n",
    "fat_cols = ['saturated_fat_100g', 'monounsaturated_fat_100g',\n",
    "            'polyunsaturated_fat_100g', 'omega_3_fat_100g',\n",
    "            '_alpha_linolenic_acid_100g', 'omega_6_fat_100g', \n",
    "            'trans_fat_100g', 'cholesterol_100g' ]\n",
    "\n",
    "carb_cols = ['_lactose_100g', 'starch_100g',  'sugars_100g', 'polyols_100g',\n",
    "              'fiber_100g', '_soluble_fiber_100g', '_insoluble_fiber_100g' ] \n",
    "\n",
    "oli_vit_cols = ['vitamin_a_100g', 'vitamin_d_100g', 'vitamin_e_100g',\n",
    "                'vitamin_k_100g', 'vitamin_c_100g', 'vitamin_b1_100g',\n",
    "                'vitamin_b2_100g', 'vitamin_pp_100g', 'vitamin_b6_100g',\n",
    "                'vitamin_b9_100g', 'folates_100g', 'vitamin_b12_100g',\n",
    "                'biotin_100g', 'pantothenic_acid_100g', 'bicarbonate_100g',\n",
    "                'potassium_100g', 'chloride_100g', 'calcium_100g',\n",
    "                'phosphorus_100g', 'iron_100g', 'magnesium_100g', 'zinc_100g',\n",
    "                'copper_100g', 'manganese_100g', 'selenium_100g', 'iodine_100g']\n",
    "\n",
    "addit_cols_cat = ['quantity_type', 'quantity_unit', 'packaging_main',\n",
    "                  'labels_main', 'allergens_main','traces_main','additives_main']\n",
    "\n",
    "addit_cols_num = ['quantity_num', 'ing_from_palm_oil_n', 'additives_n','fruit_veg_nut_100g']\n",
    "\n",
    "scores_cols = ['nutriscore', 'nutrigrade']\n",
    "\n",
    "cat_cols = ['main_category', 'categories_main','pnns2', 'pnns1', 'nova_group',\n",
    "            'brands_main', 'countries_main']\n",
    "\n",
    "misc_cols = ['alcohol_100g',  'caffeine_100g', 'cocoa_100g', 'sodium_100g']\n",
    "\n",
    "energy_cols = ['energy_from_fat_kj_100g', 'energy_kj_100g']\n",
    "\n",
    "tuple_cols = ['categories_tuple', 'brands_tuple','countries_tuple',\n",
    "              'packaging_tuple','additives_tuple','labels_tuple',\n",
    "              'allergens_tuple', 'traces_tuple']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining groups of columns\n",
    "# info_cols =  ['code','code_val','url','creator','created_datetime',\n",
    "#               'product_name', 'ingredients_text']\n",
    "\n",
    "# m_nutri_cols = ['fat_100g','carbohydrates_100g','proteins_100g','sodium_100g',\n",
    "#                 'salt_100g','fiber_100g','saturated_fat_100g','sugars_100g']\n",
    "\n",
    "# addit_cols_cat = ['quantity_type','quantity_unit', 'packaging_main',\n",
    "#                   'serving_quantity','labels_main','allergens_main',\n",
    "#                   'traces_main','additives_main']\n",
    "\n",
    "# addit_cols_num = ['quantity_num', 'ing_from_palm_oil_n', 'additives_n']\n",
    "\n",
    "# scores_cols = ['nutriscore', 'nutrigrade']\n",
    "\n",
    "# cat_cols = ['main_category', 'categories_main','pnns2', 'pnns1', 'nova_group',\n",
    "#             'brands_main', 'countries_main']\n",
    "\n",
    "# energy_cols = ['energy_from_fat_kj_100g', 'energy_kj_100g']\n",
    "\n",
    "# tuple_cols = ['categories_tuple', 'brands_tuple','countries_tuple',\n",
    "#               'packaging_tuple','additives_tuple','labels_tuple',\n",
    "#               'allergens_tuple', 'traces_tuple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Temporary\n",
    "# # tirets\n",
    "# new_cols = [c.replace('-','_') for c in df.columns]\n",
    "# df = df.rename(columns=dict(zip(df.columns,new_cols)))\n",
    "# #nova\n",
    "# df['nova_group'] = df['nova_group'].astype('object')\n",
    "# # palm oil\n",
    "# palm = ['ingredients_from_palm_oil_n', 'ingredients_that_may_be_from_palm_oil_n']\n",
    "# df['ing_from_palm_oil_n'] = df[palm].sum(axis=1)\n",
    "# # fruits veg nuts\n",
    "# df['fruit_veg_nut_100g'] = df['fruits_vegetables_nuts_100g']\\\n",
    "#                      .combine_first(df['fruits_vegetables_nuts_estimate_100g'])\n",
    "# del df['fruits_vegetables_nuts_100g'], df['fruits_vegetables_nuts_estimate_100g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting score of knn depending on k\n",
    "fig, ax1 = plt.subplots(1)\n",
    "ax1.errorbar(list(res['param_n_neighbors']), res['mean_test_score'],\n",
    "             yerr=2*res['std_test_score'], lw=1.5, capsize = 4,\n",
    "             label='mean test score')\n",
    "ax1.errorbar(list(res['param_n_neighbors']), res['mean_train_score'],\n",
    "             yerr=2*res['std_train_score'], lw=1.5, capsize = 4,\n",
    "             label='mean train score')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(list(res['param_n_neighbors']), res['mean_fit_time'],\n",
    "             label='mean fit time', c='k', lw=1.5, ls='-.')\n",
    "ax1.set_ylabel('score'), ax2.set_ylabel('time')\n",
    "ax1.set_xlabel('k value')\n",
    "ax2.set(ylim=(0.2,0.3))\n",
    "ax1.legend(loc=1), ax2.legend(loc=2)\n",
    "plt.title('GridSearchCV result with knn',\n",
    "          fontweight='bold', fontsize=12)\n",
    "fig.text(0.4,0.65,'Best score: {:.3f}'.format(best_test_score)+\\\n",
    "               '\\nBest param: '+str(gsCV.best_params_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "# -- Selecting most correlated features (see ppscore matrix below)\n",
    "cat_to_impute = 'main_category'\n",
    "vars_knn = ['categories_main']\n",
    "# ---- data with no nan\n",
    "# n_sample = \n",
    "df_tr = df[vars_knn+[cat_to_impute]].dropna(how='any')\n",
    "print('total nb of notna rows available to train the model:', df_tr.shape[0])\n",
    "# df_tr = df_tr.sample(n_sample)\n",
    "# print('selection of rows to train the model:', df_knn.shape[0])\n",
    "\n",
    "# -- Keeping only a subset with less unique values\n",
    "# ---- creating the subset\n",
    "n_uni_thresh = 500\n",
    "print(\"original 'categories_main': \", str(df_knn['categories_main'].nunique()), \"unique values.\")\n",
    "cat_occ = df['categories_main'].value_counts()\n",
    "to_keep = cat_occ[cat_occ>n_uni_thresh].index\n",
    "sub_ser = df['categories_main'].where(df['categories_main'].isin(to_keep))\n",
    "print(\"subset of 'categories_main': \", str(sub_ser.nunique()), \"unique values.\")\n",
    "# ---- visualizing to choose a threshold of unique values\n",
    "cat_occ.plot.bar(color='None', ec='r', lw=3)\n",
    "ax = plt.gca()\n",
    "ax.set(xlim=(15,50), ylim=(0,2500))\n",
    "ax.set_title(\"value_counts of 'categories_main'\", fontweight='bold')\n",
    "labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "short_labels = [s[0:7]+'.' if len(s)>7 else s for s in labels]\n",
    "ax.axes.set_xticklabels(short_labels)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.gcf().set_size_inches(8,2)\n",
    "plt.show()\n",
    "\n",
    "# Encoding dependant variables to dummy variables\n",
    "df_X_enc = pd.get_dummies(df_tr.loc[sub_ser.index])\n",
    "# ---> X to fit the model\n",
    "X = df_X_enc[vars_knn].values\n",
    "# ---> X where y missing rows\n",
    "ind_to_impute = df.loc[df[cat_to_impute].isna()].index\n",
    "X_ = df_X_enc.loc[ind_to_impute,vars_knn].values\n",
    "print('X shape (train): ', X.shape)\n",
    "print('X_ shape (to impute): ', X_.shape)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_knn.iloc[:,-1].values)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
